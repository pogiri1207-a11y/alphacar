import { Injectable, OnModuleInit } from '@nestjs/common';
import { ConfigService } from '@nestjs/config';
import {
  BedrockRuntimeClient,
  ConverseCommand,
  ConverseCommandInput
} from '@aws-sdk/client-bedrock-runtime';
import { BedrockEmbeddings } from '@langchain/aws';
import { FaissStore } from '@langchain/community/vectorstores/faiss';
import { Document } from '@langchain/core/documents';
import * as fs from 'fs';

@Injectable()
export class ChatService implements OnModuleInit {
  private embeddings: BedrockEmbeddings;
  private vectorStore: FaissStore;
  private bedrockClient: BedrockRuntimeClient;
  private readonly VECTOR_STORE_PATH = './vector_store';

  constructor(private configService: ConfigService) {}

  async onModuleInit() {
    const accessKeyId = this.configService.get<string>('AWS_ACCESS_KEY_ID') ?? '';
    const secretAccessKey = this.configService.get<string>('AWS_SECRET_ACCESS_KEY') ?? '';
    const region = this.configService.get<string>('AWS_REGION') ?? 'us-east-1';

    // 1. ì„ë² ë”© ëª¨ë¸ (LangChain)
    this.embeddings = new BedrockEmbeddings({
      region: region,
      credentials: { accessKeyId, secretAccessKey },
      model: 'amazon.titan-embed-text-v2:0',
    });

    // 2. Bedrock SDK Client (Converse APIìš©)
    this.bedrockClient = new BedrockRuntimeClient({
      region: region,
      credentials: { accessKeyId, secretAccessKey },
    });

    await this.loadVectorStore();
  }

  private async loadVectorStore() {
    if (fs.existsSync(this.VECTOR_STORE_PATH)) {
      console.log('ğŸ“‚ Loading existing vector store...');
      this.vectorStore = await FaissStore.load(this.VECTOR_STORE_PATH, this.embeddings);
    } else {
      console.log('ğŸ†• Creating new vector store...');
      this.vectorStore = await FaissStore.fromDocuments(
        [new Document({ pageContent: 'Init Data', metadata: { source: 'init' } })],
        this.embeddings
      );
      await this.vectorStore.save(this.VECTOR_STORE_PATH);
    }
  }

  async addKnowledge(content: string, source: string) {
    const doc = new Document({ pageContent: content, metadata: { source } });
    await this.vectorStore.addDocuments([doc]);
    await this.vectorStore.save(this.VECTOR_STORE_PATH);
    return { message: 'Knowledge added.', source };
  }

  // [ê¸°ì¡´ ìœ ì§€] AI í…ìŠ¤íŠ¸ ê¸°ë°˜ ì°¨ì¢… ë¶„ë¥˜ (Llama 3.3 70B)
  async classifyCar(modelName: string): Promise<string> {
    const prompt = `Classify '${modelName}' into ONE: [Sedan, SUV, Truck, Van, Light Car, Sports Car, Hatchback]. No explanation.`;
    const input: ConverseCommandInput = {
      modelId: 'us.meta.llama3-3-70b-instruct-v1:0',
      messages: [{ role: 'user', content: [{ text: prompt }] }],
      inferenceConfig: { maxTokens: 10, temperature: 0 },
    };
    try {
      const command = new ConverseCommand(input);
      const res = await this.bedrockClient.send(command);
      return res.output?.message?.content?.[0]?.text?.trim().split(/[\n,.]/)[0].trim() || 'ê¸°íƒ€';
    } catch (e) { return 'ê¸°íƒ€'; }
  }

  // =================================================================================
  // [ì‹ ê·œ ê¸°ëŠ¥] ì´ë¯¸ì§€ ì±„íŒ… (Llama 3.2 Vision + RAG Pipeline + CoT Reasoning)
  // =================================================================================

  async chatWithImage(imageBuffer: Buffer, mimeType: string = 'image/jpeg') {
    console.log("ğŸ“¸ Image received, analyzing with Llama 3.2 Vision...");

    // 1. Vision ëª¨ë¸ë¡œ ì°¨ì¢… ì‹ë³„ (ì¶”ë¡  ë¡œì§ ì ìš©ë¨)
    const identifiedCarName = await this.identifyCarWithLlama(imageBuffer, mimeType);

    if (identifiedCarName === 'NOT_CAR') {
        return {
            response: "ì£„ì†¡í•©ë‹ˆë‹¤. ì‚¬ì§„ì—ì„œ ìë™ì°¨ë¥¼ ëª…í™•í•˜ê²Œ ì‹ë³„í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì°¨ëŸ‰ì´ ì˜ ë³´ì´ëŠ” ì‚¬ì§„ìœ¼ë¡œ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.",
            context_used: [],
            identified_car: null
        };
    }

    console.log(`ğŸ“¸ Identified Car: ${identifiedCarName}`);

    // 2. ì‹ë³„ëœ ì°¨ì¢…ìœ¼ë¡œ ë²¡í„° ìŠ¤í† ì–´ ê²€ìƒ‰ (RAG)
    // ë©”ëª¨ë¦¬ì— ë¡œë“œëœ this.vectorStore ì‚¬ìš© (ë””ìŠ¤í¬ ë¡œë“œ ìµœì†Œí™”)
    const results = await this.vectorStore.similaritySearch(identifiedCarName, 10);
    const contextText = results.map(doc => doc.pageContent).join("\n");
    const sources = results.map((r) => r.metadata.source);

    // 3. ê²€ìƒ‰ëœ ì •ë³´(Context)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„¤ëª… ìƒì„± (Generate Description)
    const description = await this.generateCarDescription(identifiedCarName, contextText);

    return {
        response: description,
        context_used: sources,
        identified_car: identifiedCarName
    };
  }

  // [Helper] ì‹ë³„ëœ ì •ë³´ë¡œ ì„¤ëª… ìƒì„± (Llama 3.3 70B ì‚¬ìš©)
  private async generateCarDescription(carName: string, context: string): Promise<string> {
      const prompt = `
<|begin_of_text|><|start_header_id|>system<|end_header_id|>
You are an AI Automotive Expert at 'AlphaCar'.
An image uploaded by the user has been identified as **'${carName}'**.

Your goal is to explain this vehicle to the user based **ONLY** on the provided [Context] from our vector store.

[INSTRUCTIONS]
1. **Source of Truth**: You MUST answer based solely on the [Context]. Do not use external training data.
2. **Structure**:
   - **Introduction**: "ì—…ë¡œë“œí•˜ì‹  ì‚¬ì§„ì€ **${carName}**ì…ë‹ˆë‹¤." (Confirm the identity first).
   - **Key Features**: Summarize 3 key selling points from the context.
   - **Specs**: Mention price range or fuel efficiency if available in the context.
   - **Dealer Persona**: Be professional yet friendly.
3. **Language**: Output in **Korean (Hangul)**.

[Context (Vector Store Data)]
${context}

<|eot_id|><|start_header_id|>user<|end_header_id|>
ì´ ì°¨ì— ëŒ€í•´ ìš°ë¦¬ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìì„¸íˆ ì„¤ëª…í•´ì¤˜.
<|eot_id|><|start_header_id|>assistant<|end_header_id|>
`;

      const input: ConverseCommandInput = {
        modelId: 'us.meta.llama3-3-70b-instruct-v1:0',
        messages: [{ role: 'user', content: [{ text: prompt }] }],
        inferenceConfig: { maxTokens: 2048, temperature: 0.2 },
      };

      try {
        const command = new ConverseCommand(input);
        const response = await this.bedrockClient.send(command);
        return response.output?.message?.content?.[0]?.text || 'ì°¨ëŸ‰ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.';
      } catch (e) {
        console.error("ğŸ”¥ Bedrock Description Gen Error:", e);
        return 'ì°¨ëŸ‰ ì„¤ëª… ìƒì„± ì‹¤íŒ¨';
      }
  }

  // [Helper] ì´ë¯¸ì§€ ì‹ë³„ (Llama 3.2 90B Vision) - ì¶”ë¡ (Reasoning) ë¡œì§ ê°•í™”
  private async identifyCarWithLlama(imageBuffer: Buffer, mimeType: string): Promise<string> {
    const modelId = 'us.meta.llama3-2-90b-instruct-v1:0';

    const prompt = `
<|begin_of_text|><|start_header_id|>system<|end_header_id|>
You are an expert automotive visual recognition AI.
Your task is to identify the vehicle in the image with extreme precision, distinguishing between similar boxy vehicles like Vans, SUVs, and Pickup Trucks.

[CRITICAL ANALYSIS STEPS]
Before giving the final answer, you MUST analyze the image step-by-step:
1. **Emblem/Logo Check**: Look specifically at the logo.
   - Is it 'Kia' (KN or Oval)? -> Then consider Carnival/Sorento.
   - Is it 'SsangYong'/'KGM' (Winged logo, Two Dragons, or 'KG')? -> Then consider Musso, Rexton, Torres, Actyon.
2. **Body Type Check**:
   - Open Cargo Bed? -> It is a **Pickup Truck** (e.g., Musso, Rexton Sports Khan). It is NOT a Carnival.
   - Sliding Doors? -> It is a **Minivan** (e.g., Carnival).
   - Sloping Coupe Roof? -> It might be an Actyon or XM3.
3. **Final Decision**: Combine the logo and body type to confirm the model.

[OUTPUT FORMAT]
You must output in the following structure exactly:

Reasoning: [Describe the logo, grill, and body type you see in English]
Final Answer: [Manufacturer ModelName in Korean]

[EXAMPLES]
User: 
Assistant:
Reasoning: I see a winged logo on the grill, which is SsangYong. It has an open cargo bed in the rear, making it a pickup truck. It looks like the Khan model.
Final Answer: ìŒìš© ë ‰ìŠ¤í„´ ìŠ¤í¬ì¸  ì¹¸

User: 
Assistant:
Reasoning: The logo is the new KN logo. It has a long body with sliding door rails. It is a minivan.
Final Answer: ê¸°ì•„ ì¹´ë‹ˆë°œ

User: 

[Image of a Dog]

Assistant:
Reasoning: This is an animal, not a vehicle.
Final Answer: NOT_CAR
<|eot_id|><|start_header_id|>user<|end_header_id|>
Identify the car in this image following the steps above.
<|eot_id|><|start_header_id|>assistant<|end_header_id|>
`;

    const format = mimeType === 'image/png' ? 'png' :
                   mimeType === 'image/webp' ? 'webp' :
                   mimeType === 'image/gif' ? 'gif' : 'jpeg';

    const input: ConverseCommandInput = {
      modelId: modelId,
      messages: [
        {
          role: 'user',
          content: [
            {
              image: {
                format: format as any, // Type casting for safety
                source: { bytes: imageBuffer },
              },
            },
            { text: prompt },
          ],
        },
      ],
      // í† í°ì„ ì¡°ê¸ˆ ë” ëŠ˜ë ¤ì¤ë‹ˆë‹¤ (ì¶”ë¡  ê¸€ì„ ì¨ì•¼ í•˜ë¯€ë¡œ)
      inferenceConfig: { maxTokens: 300, temperature: 0.1 },
    };

    try {
      const command = new ConverseCommand(input);
      const response = await this.bedrockClient.send(command);

      const fullText = response.output?.message?.content?.[0]?.text || '';
      console.log("ğŸ¤– Vision Thinking Process:", fullText); // ë¡œê·¸ë¡œ ì¶”ë¡  ê³¼ì • í™•ì¸ ê°€ëŠ¥

      // íŒŒì‹± ë¡œì§: "Final Answer:" ë’·ë¶€ë¶„ë§Œ ì¶”ì¶œ
      const match = fullText.match(/Final Answer:\s*(.*)/i);
      
      let identifiedName = 'NOT_CAR';
      if (match && match[1]) {
          identifiedName = match[1].trim();
      } else if (fullText.includes("NOT_CAR")) {
          identifiedName = "NOT_CAR";
      } else {
          // í˜•ì‹ì´ ì•ˆ ë§ì„ ê²½ìš° ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ í•œê¸€/ì˜ì–´ ëª¨ë¸ëª… ì¶”ì • (Fallback)
          identifiedName = fullText.replace(/Reasoning:[\s\S]*?Final Answer:/i, "").trim();
      }

      // í›„ì²˜ë¦¬: ë¶ˆí•„ìš”í•œ íŠ¹ìˆ˜ë¬¸ì ì œê±°
      identifiedName = identifiedName.replace(/\.$/, '').trim();

      if (identifiedName.includes('NOT_CAR')) return 'NOT_CAR';
      
      return identifiedName;

    } catch (e) {
      console.error("ğŸ”¥ Bedrock Vision Error:", e);
      return 'NOT_CAR';
    }
  }

  // =================================================================================

  async chat(userMessage: string) {
    // 1. RAG ê²€ìƒ‰
    // ê²€ìƒ‰ëŸ‰ì„ 50ê°œë¡œ ìœ ì§€í•©ë‹ˆë‹¤.
    let results = await this.vectorStore.similaritySearch(userMessage, 50);

    const context = results.map((r) => r.pageContent).join('\n\n');
    const sources = results.map((r) => r.metadata.source);

    console.log(`ğŸ” Context Length: ${context.length} characters`);

    // ğŸ‘‡ [FIX: ë¹„êµ ëª¨ë“œ ê°ì§€ ë¡œì§]
    const comparisonKeywords = ['ë¹„êµ', 'ëŒ€ë¹„', 'ë­ê°€ ë”', 'ì°¨ì´'];
    const isComparisonQuery = comparisonKeywords.some(keyword => userMessage.includes(keyword)) &&
                              (userMessage.includes('ì˜ë‚˜íƒ€') && userMessage.includes('K5')); // ì˜ˆì‹œ ë¡œì§ ìœ ì§€

    // 2. ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ìµœì‹  ì—…ë°ì´íŠ¸: ë”œëŸ¬ í˜ë¥´ì†Œë‚˜ ë° ê°€ë“œë ˆì¼ ê°•í™”)
    let systemPrompt = `
    You are the AI Automotive Specialist for 'AlphaCar'.

    [CORE RULES - STRICT COMPLIANCE]
    1. **LANGUAGE**: Answer strictly in **Korean (Hangul)**. No Hanja.
    2. **GROUNDING**: Answer SOLELY based on the provided [Context].
    3. **GUARDRAIL**: If the user asks about Non-Automotive topics, REJECT immediately.
    4. **Image**: The provided context contains image paths (labeled as 'imageUrl' or 'ì´ë¯¸ì§€ê²½ë¡œ'). You MUST extract the exact image path associated with the analyzed vehicle from the context and include it in the response. Do not generate a fake URL; use only the path provided in the source data.

    [CONVERSATION FLOW - KEEP IT ALIVE]
    **Do NOT just answer and stop.** Always end your response with a **Follow-up Question** to guide the user.

    - **If you recommended cars**: "ì´ ì¤‘ì—ì„œ ë§ˆìŒì— ë“œëŠ” ëª¨ë¸ì´ ìˆìœ¼ì‹ ê°€ìš”? ì•„ë‹ˆë©´ ë‹¤ë¥¸ ì¡°ê±´(ì˜ˆ: ì—°ë¹„, ë””ìì¸)ìœ¼ë¡œ ë” ì°¾ì•„ë³¼ê¹Œìš”?"
    - **If you gave a price**: "ìƒê°í•˜ì‹  ì˜ˆì‚° ë²”ìœ„ì— ë§ìœ¼ì‹ ê°€ìš”? í• ë¶€ ê²¬ì ì´ë‚˜ ì˜µì…˜ ì •ë³´ë„ ì•Œë ¤ë“œë¦´ê¹Œìš”?"
    - **If info is missing**: "ë” ì •í™•í•œ ì¶”ì²œì„ ìœ„í•´ ì„ í˜¸í•˜ì‹œëŠ” ë¸Œëœë“œë‚˜ ì—°ë£Œ íƒ€ì…(ì „ê¸°/ê°€ì†”ë¦°)ì„ ì•Œë ¤ì£¼ì‹œê² ì–´ìš”?"
    - **General**: Act like a friendly and proactive car dealer.

    [RESPONSE_STRATEGY]
    1. **QUANTITY**: Recommend at least 3 different models if possible.
    2. **FORMAT**: Use a numbered list.
    3. **Persona**: Adapt to the context of the question and respond kindly and professionally, acting as if a **seasoned car dealer** is consulting face-to-face. (Avoid a stiff, robotic tone).
       - **âš ï¸ Data Guardrails**: Even while maintaining a natural conversation flow, you **MUST** state vehicle specifications, prices, and features **EXACTLY as provided in the [Context]**. Do not hallucinate or invent non-existent options or prices for the sake of roleplay.

    // ğŸ‘‡ [ìµœì¢… FIX] ë¹„êµ ì¿¼ë¦¬ì¼ ê²½ìš°, êµ¬ì¡°í™”ëœ ë¸”ë¡ ì¶œë ¥ì„ ê°•ì œí•˜ì—¬ ì •ë³´ ëˆ„ë½ì„ ë§‰ìŠµë‹ˆë‹¤.
    ${isComparisonQuery ? `
    4. **COMPARISON_RULE (CRITICAL)**: The user wants a side-by-side comparison. YOU MUST NOT fail to find either model. Search the Context for both "ì˜ë‚˜íƒ€" and "K5". Your entire response MUST output two distinct, separate content blocks (one for Sonata, one for K5) separated only by TWO consecutive newlines (\\n\\n).
    5. **BLOCK_STRUCTURE**: Each block MUST start with the image link for the model it describes, followed immediately by a short summary of its Price Range and Key Options text. DO NOT output a comparison table. DO NOT output the block numbers (1, 2).
    ` : `
    4. **IMAGE_PRIORITY**: If the context provides the ImageURL and BaseTrimId for the car you are discussing, you MUST include its image and link following the [IMAGE RENDERING & LINKING LOGIC].
    `}

    [SMART FILTERING LOGIC]
    1. **Price Flexibility**: Allow Â±10% margin.
    2. **Type Filtering**:
        - "Sedan" -> Sedan/Coupe/Hatchback.
        - "SUV" -> SUV/RV.
    3. **Scenarios**:
        - "Camping": SUV, Van.
        - "Commute/First Car": Compact Sedan, Hybrid, Light Car.

    [IMAGE RENDERING & LINKING LOGIC]
    - MUST display images if 'ImageURL' exists in context.
    - **CRITICAL**: You MUST wrap the image in a link to the quote page.

    - **â›” STRICT RULE (NO RAW URLs)**:
      - Do NOT write the raw Image URL (http://...) as plain text in the response.
      - ONLY output the URL inside the Markdown link syntax.

    - **ID Selection Rules (Smart Linking)**:
      1. Find the **BaseTrimId** value from the [ì‹œìŠ¤í…œ ë°ì´í„°] section of the vehicle you are describing.
      2. **ABSOLUTELY MUST**: The resulting link MUST use the actual ID value, not a placeholder.

    - **Link Format (Template - MUST FOLLOW)**:
      [![Car Model Name](ImageURL)](/quote/personal/result?trimId=ì‹¤ì œ_BaseTrimId_ê°’)

    [Context]
    ${context}
    `;

    // 3. Bedrock Converse API (Llama 3.3 70B - í…ìŠ¤íŠ¸ ìƒì„±ìš©)
    const guardrailId = this.configService.get<string>('BEDROCK_GUARDRAIL_ID');
    const guardrailVersion = this.configService.get<string>('BEDROCK_GUARDRAIL_VERSION') || 'DRAFT';

    const input: ConverseCommandInput = {
      modelId: 'us.meta.llama3-3-70b-instruct-v1:0',
      messages: [{ role: 'user', content: [{ text: userMessage }] }],
      system: [{ text: systemPrompt }],
      inferenceConfig: { maxTokens: 2048, temperature: 0.2 }, // í† í° ìˆ˜ 2048ë¡œ ìµœì í™”
    };

    if (guardrailId && guardrailId.length > 5) {
        input.guardrailConfig = {
            guardrailIdentifier: guardrailId,
            guardrailVersion: guardrailVersion,
            trace: 'enabled',
        };
        console.log(`ğŸ›¡ï¸ Guardrail Active: ${guardrailId} (${guardrailVersion})`);
    }

    try {
      const command = new ConverseCommand(input);
      const response = await this.bedrockClient.send(command);

      if (response.stopReason === 'guardrail_intervened') {
          console.log("ğŸš« Blocked by AWS Guardrail!");
          return {
              response: "ğŸš« ì£„ì†¡í•©ë‹ˆë‹¤. ê·¸ ì§ˆë¬¸ì€ ë‹µë³€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
              context_used: [],
          };
      }

      const outputText = response.output?.message?.content?.[0]?.text || '';
      return { response: outputText, context_used: sources };

    } catch (e: any) {
      console.error("ğŸ”¥ AWS Bedrock Error:", e.message);
      if (e.name === 'ValidationException' && e.message.includes('guardrail')) {
         return {
             response: `âš ï¸ [System Error] Guardrail Config Error.\n${e.message}`,
             context_used: []
         };
      }
      return {
          response: "ì£„ì†¡í•©ë‹ˆë‹¤. AI ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
          context_used: []
      };
    }
  }
}
