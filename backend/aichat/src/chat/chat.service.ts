import { Injectable, OnModuleInit } from '@nestjs/common';
import { ConfigService } from '@nestjs/config';
import {
  BedrockRuntimeClient,
  ConverseCommand,
  ConverseCommandInput
} from '@aws-sdk/client-bedrock-runtime';
import { BedrockEmbeddings } from '@langchain/aws';
import { FaissStore } from '@langchain/community/vectorstores/faiss';
import { Document } from '@langchain/core/documents';
import * as fs from 'fs';

@Injectable()
export class ChatService implements OnModuleInit {
  private embeddings: BedrockEmbeddings;
  private vectorStore: FaissStore;
  private bedrockClient: BedrockRuntimeClient;
  private readonly VECTOR_STORE_PATH = './vector_store';

  constructor(private configService: ConfigService) {}

  async onModuleInit() {
    const accessKeyId = this.configService.get<string>('AWS_ACCESS_KEY_ID') ?? '';
    const secretAccessKey = this.configService.get<string>('AWS_SECRET_ACCESS_KEY') ?? '';
    const region = this.configService.get<string>('AWS_REGION') ?? 'us-east-1';

    this.embeddings = new BedrockEmbeddings({
      region: region,
      credentials: { accessKeyId, secretAccessKey },
      model: 'amazon.titan-embed-text-v2:0',
    });

    this.bedrockClient = new BedrockRuntimeClient({
      region: region,
      credentials: { accessKeyId, secretAccessKey },
    });

    await this.loadVectorStore();
  }

  private async loadVectorStore() {
    if (fs.existsSync(this.VECTOR_STORE_PATH)) {
      console.log('ğŸ“‚ Loading existing vector store...');
      this.vectorStore = await FaissStore.load(this.VECTOR_STORE_PATH, this.embeddings);
    } else {
      console.log('ğŸ†• Creating new vector store...');
      this.vectorStore = await FaissStore.fromDocuments(
        [new Document({ pageContent: 'Init Data', metadata: { source: 'init' } })],
        this.embeddings
      );
      await this.vectorStore.save(this.VECTOR_STORE_PATH);
    }
  }

  async addKnowledge(content: string, source: string) {
    const doc = new Document({ pageContent: content, metadata: { source } });
    await this.vectorStore.addDocuments([doc]);
    await this.vectorStore.save(this.VECTOR_STORE_PATH);
    return { message: 'Knowledge added.', source };
  }

  async classifyCar(modelName: string): Promise<string> {
    const prompt = `Classify '${modelName}' into ONE: [Sedan, SUV, Truck, Van, Light Car, Sports Car, Hatchback]. No explanation.`;
    const input: ConverseCommandInput = {
      modelId: 'us.meta.llama3-3-70b-instruct-v1:0',
      messages: [{ role: 'user', content: [{ text: prompt }] }],
      inferenceConfig: { maxTokens: 10, temperature: 0 },
    };
    try {
      const command = new ConverseCommand(input);
      const res = await this.bedrockClient.send(command);
      return res.output?.message?.content?.[0]?.text?.trim().split(/[\n,.]/)[0].trim() || 'ê¸°íƒ€';
    } catch (e) { return 'ê¸°íƒ€'; }
  }

  // =================================================================================
  // [ì´ë¯¸ì§€ ì±„íŒ…]
  // =================================================================================

  async chatWithImage(imageBuffer: Buffer, mimeType: string = 'image/jpeg') {
    console.log("ğŸ“¸ Image received, analyzing with Llama 3.2 Vision...");

    try {
      // 1. ì°¨ì¢… ì‹ë³„
      let identifiedCarName = await this.identifyCarWithLlama(imageBuffer, mimeType);
      
      // â˜… [ìˆ˜ì •] ì‹ë³„ ê²°ê³¼ ì „ì²˜ë¦¬ (ì•ë’¤ ê³µë°± ì œê±° ë° ìœ íš¨ì„± ê²€ì‚¬)
      if (identifiedCarName) {
          identifiedCarName = identifiedCarName.trim();
      }

      console.log(`ğŸ“¸ Identified Car Result: "${identifiedCarName}"`);

      // â˜… [ìˆ˜ì •] ì‹¤íŒ¨ ì¡°ê±´ ê°•í™” (ë¹ˆ ë¬¸ìì—´, null, undefined, NOT_CAR ëª¨ë‘ ì°¨ë‹¨)
      if (!identifiedCarName || identifiedCarName === 'NOT_CAR' || identifiedCarName.length < 2) {
        return {
            response: "ì£„ì†¡í•©ë‹ˆë‹¤. ì‚¬ì§„ì—ì„œ ìë™ì°¨ë¥¼ ëª…í™•í•˜ê²Œ ì‹ë³„í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì°¨ëŸ‰ì´ ë” ì˜ ë³´ì´ëŠ” ì‚¬ì§„ìœ¼ë¡œ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.",
            context_used: [],
            identified_car: null
        };
      }

      // 2. ê²€ìƒ‰ (RAG)
      const results = await this.vectorStore.similaritySearch(identifiedCarName, 10);
      
      // â˜… [ì¶”ê°€] ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ì„ ê²½ìš° ì˜ˆì™¸ ì²˜ë¦¬
      if (!results || results.length === 0) {
          return {
              response: `ì£„ì†¡í•©ë‹ˆë‹¤. ì‚¬ì§„ì˜ ì°¨ëŸ‰(${identifiedCarName})ê³¼ ì¼ì¹˜í•˜ëŠ” ì •ë³´ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.`,
              context_used: [],
              identified_car: identifiedCarName
          };
      }

      const contextText = results.map(doc => doc.pageContent).join("\n");
      const sources = results.map((r) => r.metadata.source);

      // 3. ì„¤ëª… ìƒì„±
      const description = await this.generateCarDescription(identifiedCarName, contextText);

      return {
          response: description,
          context_used: sources,
          identified_car: identifiedCarName
      };

    } catch (e: any) {
      console.error("ğŸ”¥ chatWithImage Error:", e.message);
      console.error("ğŸ”¥ Error Stack:", e.stack);
      console.error("ğŸ”¥ Error Details:", JSON.stringify(e, Object.getOwnPropertyNames(e)));
      return {
        response: "ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.",
        context_used: [],
        identified_car: null
      };
    }
  }

  private async generateCarDescription(carName: string, context: string): Promise<string> {
      const prompt = `
<|begin_of_text|><|start_header_id|>system<|end_header_id|>
You are an AI Automotive Expert at 'AlphaCar'.
An image uploaded by the user has been identified as **'${carName}'**.

Your goal is to explain this vehicle to the user based **ONLY** on the provided [Context] from our vector store.

[INSTRUCTIONS]
1. **Source of Truth**: You MUST answer based solely on the [Context]. Do not use external training data.
2. **Structure**:
   - **Introduction**: "ì—…ë¡œë“œí•˜ì‹  ì‚¬ì§„ì€ **${carName}**ì…ë‹ˆë‹¤."
   - **Image Display (CRITICAL)**: You MUST display the car image from the context.
   - **Key Features**: Summarize 3 key selling points.
   - **Specs**: Mention price range or fuel efficiency.
   - **Call to Action**: Encourage checking the detailed quote.
3. **Language**: Output in **Korean (Hangul)**.

[IMAGE RENDERING & LINKING LOGIC - STRICT]
- The user MUST be able to click the image to see the quote.
- **Step 1**: Find 'ì´ë¯¸ì§€URL' (or 'ImageURL') in the [Context].
- **Step 2**: Find 'BaseTrimId' in the [ì‹œìŠ¤í…œ ë°ì´í„°] section of the [Context].
- **Step 3**: Find 'ëª¨ë¸ëª…' (Model Name) in the [ì°¨ëŸ‰ ì •ë³´] section of the [Context].
- **Step 4**: Generate the image link using this EXACT Markdown format:

  [![${carName}](ì´ë¯¸ì§€URL_ê°’)](/quote/personal/result?trimId=BaseTrimId_ê°’&modelName=ëª¨ë¸ëª…_ê°’)

- **WARNING**: Do NOT output raw URLs. Use the Markdown link format above. Replace '..._ê°’' placeholders with actual values found in the context.

[Context (Vector Store Data)]
${context}

<|eot_id|><|start_header_id|>user<|end_header_id|>
ì´ ì°¨ì— ëŒ€í•´ ìš°ë¦¬ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìì„¸íˆ ì„¤ëª…í•´ì£¼ê³ , ê²¬ì ì„ ë³¼ ìˆ˜ ìˆê²Œ ì‚¬ì§„ì— ë§í¬ë¥¼ ê±¸ì–´ì¤˜.
<|eot_id|><|start_header_id|>assistant<|end_header_id|>
`;

      const input: ConverseCommandInput = {
        modelId: 'us.meta.llama3-3-70b-instruct-v1:0',
        messages: [{ role: 'user', content: [{ text: prompt }] }],
        inferenceConfig: { maxTokens: 2048, temperature: 0.2 },
      };

      try {
        const command = new ConverseCommand(input);
        const response = await this.bedrockClient.send(command);
        return response.output?.message?.content?.[0]?.text || 'ì°¨ëŸ‰ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.';
      } catch (e) {
        console.error("ğŸ”¥ Bedrock Description Gen Error:", e);
        return 'ì°¨ëŸ‰ ì„¤ëª… ìƒì„± ì‹¤íŒ¨';
      }
  }

  private async identifyCarWithLlama(imageBuffer: Buffer, mimeType: string): Promise<string> {
    const modelId = 'us.meta.llama3-2-90b-instruct-v1:0';

    const prompt = `
<|begin_of_text|><|start_header_id|>system<|end_header_id|>
You are an expert automotive visual recognition AI.
Your task is to identify the vehicle in the image with extreme precision.

[OUTPUT FORMAT]
Reasoning: [Reasoning in English]
Final Answer: [Manufacturer ModelName in Korean]

[EXAMPLES]
User: [Image]
Assistant:
Reasoning: I see the KN logo and sliding doors. It is a minivan.
Final Answer: ê¸°ì•„ ì¹´ë‹ˆë°œ

User: [Image]
Assistant:
Reasoning: This is a dog.
Final Answer: NOT_CAR
<|eot_id|><|start_header_id|>user<|end_header_id|>
Identify the car in this image.
<|eot_id|><|start_header_id|>assistant<|end_header_id|>
`;

    const format = mimeType.includes('png') ? 'png' :
                   mimeType.includes('webp') ? 'webp' :
                   mimeType.includes('gif') ? 'gif' : 'jpeg';

    const input: ConverseCommandInput = {
      modelId: modelId,
      messages: [
        {
          role: 'user',
          content: [
            {
              image: {
                format: format as any,
                source: { bytes: imageBuffer },
              },
            },
            { text: prompt },
          ],
        },
      ],
      inferenceConfig: { maxTokens: 300, temperature: 0.1 },
    };

    try {
      const command = new ConverseCommand(input);
      const response = await this.bedrockClient.send(command);
      const fullText = response.output?.message?.content?.[0]?.text || '';
      console.log("ğŸ¤– Vision Thinking Process:", fullText);

      // â˜… [ìˆ˜ì •] íŒŒì‹± ë¡œì§ ê°•í™”
      // 1. Final Answer ì •ê·œì‹ ì‹œë„
      let match = fullText.match(/Final Answer:\s*(.+)/i);
      let identifiedName = '';

      if (match && match[1]) {
          identifiedName = match[1].trim();
      } else {
          // 2. ì •ê·œì‹ ì‹¤íŒ¨ ì‹œ, NOT_CAR í‚¤ì›Œë“œ í™•ì¸
          if (fullText.includes("NOT_CAR")) {
              return 'NOT_CAR';
          }
          // 3. ê·¸ê²ƒë„ ì•„ë‹ˆë©´ ë§ˆì§€ë§‰ ì¤„ì„ ì •ë‹µìœ¼ë¡œ ê°„ì£¼ (ìµœí›„ì˜ ìˆ˜ë‹¨)
          const lines = fullText.trim().split('\n');
          const lastLine = lines[lines.length - 1].trim();
          // ë§ˆì§€ë§‰ ì¤„ì´ ë„ˆë¬´ ê¸¸ë©´(ì„¤ëª…ë¬¸ì´ë©´) ë¬´ì‹œ
          if (lastLine.length > 0 && lastLine.length < 50) {
             identifiedName = lastLine;
          }
      }

      // íŠ¹ìˆ˜ë¬¸ì ì œê±° ë° ì •ë¦¬
      identifiedName = identifiedName.replace(/[.,;!"']/g, '').trim();
      
      // ìµœì¢… ê²€ì¦
      if (!identifiedName || identifiedName.toUpperCase() === 'NOT_CAR') return 'NOT_CAR';
      
      return identifiedName;

    } catch (e: any) {
      console.error("ğŸ”¥ Bedrock Vision Error:", e.message);
      console.error("ğŸ”¥ Bedrock Vision Error Stack:", e.stack);
      if (e.name === 'ValidationException' || e.name === 'AccessDeniedException') {
        console.error("ğŸ”¥ AWS Bedrock API Error - Check credentials and model access");
      }
      return 'NOT_CAR';
    }
  }

  // =================================================================================

  async chat(userMessage: string) {
    let results = await this.vectorStore.similaritySearch(userMessage, 20);

    const context = results.map((r) => r.pageContent).join('\n\n');
    const sources = results.map((r) => r.metadata.source);

    console.log(`ğŸ” Context Length: ${context.length} characters`);

    const comparisonKeywords = ['ë¹„êµ', 'ëŒ€ë¹„', 'ë­ê°€ ë”', 'ì°¨ì´'];
    const isComparisonQuery = comparisonKeywords.some(keyword => userMessage.includes(keyword)) &&
                              (userMessage.includes('ì˜ë‚˜íƒ€') && userMessage.includes('K5'));

    let systemPrompt = `
    You are the AI Automotive Specialist for 'AlphaCar'.

    [CORE RULES]
    1. **LANGUAGE**: Answer strictly in **Korean (Hangul)**.
    2. **GROUNDING**: Answer SOLELY based on the provided [Context].
    3. **GUARDRAIL**: Reject non-automotive topics.

    [IMAGE RENDERING & LINKING LOGIC - CRITICAL]
    - If the context contains 'ImageURL' and 'BaseTrimId' for the suggested car, you **MUST** display the image wrapped in a link.
    - **Purpose**: Clicking the image should take the user to the quote page.
    - **STRICT Format**:
      [![Car Name](ImageURL_ê°’)](/quote/personal/result?trimId=BaseTrimId_ê°’&modelName=ëª¨ë¸ëª…_ê°’)

    - **Instruction**:
      1. Extract 'ImageURL' from the context.
      2. Extract 'BaseTrimId' from the [ì‹œìŠ¤í…œ ë°ì´í„°] section.
      3. Extract 'ëª¨ë¸ëª…' (Model Name) from the [ì°¨ëŸ‰ ì •ë³´] section.
      4. Combine them into the Markdown link above. Replace '..._ê°’' placeholders with the actual values found in the context.

    [RESPONSE STRATEGY]
    - Act like a friendly, professional car dealer.
    - End with a follow-up question.

    ${isComparisonQuery ? `
    [COMPARISON MODE]
    - Output two distinct blocks for each car.
    - Start each block with the clickable image link (Format above).
    - Compare Price and Key Options.
    ` : ''}

    [Context]
    ${context}
    `;

    const guardrailId = this.configService.get<string>('BEDROCK_GUARDRAIL_ID');
    const guardrailVersion = this.configService.get<string>('BEDROCK_GUARDRAIL_VERSION') || 'DRAFT';

    const input: ConverseCommandInput = {
      modelId: 'us.meta.llama3-3-70b-instruct-v1:0',
      messages: [{ role: 'user', content: [{ text: userMessage }] }],
      system: [{ text: systemPrompt }],
      inferenceConfig: { maxTokens: 2048, temperature: 0.2 },
    };

    if (guardrailId && guardrailId.length > 5) {
        input.guardrailConfig = {
            guardrailIdentifier: guardrailId,
            guardrailVersion: guardrailVersion,
            trace: 'enabled',
        };
    }

    try {
      const command = new ConverseCommand(input);
      const response = await this.bedrockClient.send(command);

      if (response.stopReason === 'guardrail_intervened') {
          return { response: "ğŸš« ì£„ì†¡í•©ë‹ˆë‹¤. ê·¸ ì§ˆë¬¸ì€ ë‹µë³€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", context_used: [] };
      }

      const outputText = response.output?.message?.content?.[0]?.text || '';
      return { response: outputText, context_used: sources };

    } catch (e: any) {
      console.error("ğŸ”¥ AWS Bedrock Error:", e.message);
      return { response: "ì£„ì†¡í•©ë‹ˆë‹¤. AI ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.", context_used: [] };
    }
  }
}
